{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bokeh.charts import output_notebook, Bar, show, output_file, Line, BoxPlot, Scatter\n",
    "from bokeh.layouts import row\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "output_notebook() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data.csv\",index_col=0,parse_dates=True)\n",
    "\n",
    "\n",
    "rich_weekday = lambda c: -1 if c[\"holiday\"] else c[\"weekday\"]\n",
    "\n",
    "dataset.workingday = dataset.workingday==1\n",
    "dataset.holiday = dataset.holiday==1\n",
    "dataset[\"hour\"] =  dataset.index.hour\n",
    "dataset[\"weekday\"] = dataset.index.weekday\n",
    "dataset[\"season_s\"] = dataset.season.map({1:\"Printemps\",2:\"Ete\",3:\"Automne\",4:\"Hiver\"})\n",
    "dataset[\"weather_s\"] = dataset.weather.map({1:\"clear\",2:\"cloudy\",3:\"light rain\",4:\"crappy\"})\n",
    "dataset[\"rich_weekday\"] = dataset.apply( rich_weekday, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "dset =  pd.read_csv(\"data.csv\",index_col=0,parse_dates=True)\n",
    "label = dataset[\"registered\"] \n",
    "del dset[\"count\"], dset[\"registered\"], dset[\"casual\"]\n",
    "dset[\"hour\"] =  dset.index.hour\n",
    "dset[\"weekday\"] = dset.index.weekday\n",
    "#dset[\"hour_weekend\"] = dset[\"hour\"] * dataset.weekday.map(lambda i: 0 if (i in [6,7]) else 1)\n",
    "#dset[\"hour_workweek\"] = dset[\"hour\"] * dataset.weekday.map(lambda i: 1 if (i in [6,7]) else 0)   \n",
    "dset[\"h_wd\"] = dset.weekday*100+dataset.hour\n",
    "\n",
    "dset_scaled = preprocessing.scale(dset)\n",
    "pca = PCA(n_components=\"mle\")\n",
    "\n",
    "dt = DecisionTreeRegressor(max_depth=25)\n",
    "clf = AdaBoostRegressor(n_estimators=100,base_estimator=dt)\n",
    "#clf = GradientBoostingRegressor(n_estimators=300,max_depth=4) \n",
    "#clf = Ridge(normalize=True, alpha=.1, tol=1e-15)\n",
    "estimators = [('reduce_dim', pca), ('clf',clf)]\n",
    "pipe = Pipeline(estimators)\n",
    "#scores = cross_val_score(clf, dset, label,cv=20,verbose=1,scoring=\"neg_mean_absolute_error\",n_jobs=6)\n",
    "scores = cross_val_score(clf, dset, label,cv=5,verbose=1,scoring=\"neg_mean_squared_error\",n_jobs=6)                          \n",
    "print(\"Avg dist to estimate: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimator = pipe.fit(dset,label)\n",
    "full_dset =  pd.read_csv(\"data.csv\",index_col=0,parse_dates=True)\n",
    "full_dset[\"hour\"] =  dset.index.hour\n",
    "full_dset[\"weekday\"] = dset.index.weekday\n",
    "full_dset[\"predicted\"] = estimator.predict(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col = \"predicted\"\n",
    "gg =  full_dset.groupby([\"weekday\",\"hour\"])[col].mean().reset_index().rename(columns={\"level_0\":\"weekday\",\"level_1\":\"hour\"})\n",
    "\n",
    "gg[\"weekday\"] = gg.weekday.map({0:\"Mon\",1:\"Tue\",2:\"Wed\",3:\"Thu\",4:\"Fri\",5:\"Sat\",6:\"Sun\",-1:\"Holiday\"})\n",
    "\n",
    "b = Line(gg,x=\"hour\",y=col,color=\"weekday\")\n",
    "\n",
    "show(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "print clf.get_params()\n",
    "#param_grid = [{'learning_rate':[1],'base_estimator__max_depth':[2,5,10],'n_estimators':[10,100,500,1000,5000]}]\n",
    "param_grid = [{'learning_rate':[1],'max_depth':[2,5,10,20,30],'n_estimators':[10,100,500,1000,5000]}]\n",
    "gscv = GridSearchCV(\n",
    "    estimator = clf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"r2\",\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=6\n",
    ")\n",
    "\n",
    "f = gscv.fit(dset, label)\n",
    "\n",
    "print f.best_estimator_\n",
    "print f.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "dset_scaled = preprocessing.scale(dset)\n",
    "clf = svm.SVR(kernel='rbf',C=1,verbose=True, cache_size=1000)\n",
    "#clf = svm.SVR(C=1e3,verbose=True)\n",
    "scores = cross_val_score(clf, dset, label,cv=10,verbose=3,scoring=\"neg_median_absolute_error\",n_jobs=6)\n",
    "scores.mean()  \n",
    "print(\"Avg dist to estimate: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_val_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[\"count\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tpot import TPOTRegressor\n",
    "pipeline_optimizer = TPOTRegressor(generations=5, population_size=20, num_cv_folds=5, random_state=42, verbosity=2)\n",
    "#(fits by default on lean squared errror)\n",
    "label = dataset[\"registered\"] \n",
    "dset =  pd.read_csv(\"data.csv\",index_col=0,parse_dates=True)\n",
    "del dset[\"count\"], dset[\"registered\"], dset[\"casual\"]\n",
    "dset[\"hour\"] =  dset.index.hour\n",
    "dset[\"weekday\"] = dset.index.weekday\n",
    "#dset[\"hour_weekend\"] = dset[\"hour\"] * dataset.weekday.map(lambda i: 0 if (i in [6,7]) else 1)\n",
    "#dset[\"hour_workweek\"] = dset[\"hour\"] * dataset.weekday.map(lambda i: 1 if (i in [6,7]) else 0)   \n",
    "dset[\"h_wd\"] = dset.weekday*100+dataset.hour\n",
    "\n",
    "pipeline_optimizer.fit(dset, label)\n",
    "print(pipeline_optimizer.score(dset, label))\n",
    "pipeline_optimizer.export('tpot_exported_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
