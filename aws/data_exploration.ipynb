{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## loading data/libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-20T19:09:44.933314",
     "start_time": "2017-01-20T19:09:44.913874"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import calendar\n",
    "from bokeh.charts import output_notebook, Scatter, Bar, show, output_file, Line, BoxPlot, Scatter\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import hplot\n",
    "output_notebook() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-20T18:12:25.340898",
     "start_time": "2017-01-20T18:12:25.168430"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INPUT=\"data/device_failure.csv\" \n",
    "dataset = pd.read_csv(INPUT,index_col=[0,1],parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-20T18:12:26.110610",
     "start_time": "2017-01-20T18:12:26.102261"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_dset = dataset[[\"failure\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-20T18:12:27.150655",
     "start_time": "2017-01-20T18:12:27.133185"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_failures_per_device = label_dset.groupby(level=1).agg(sum)\n",
    "total_failures_per_device[\"failure\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each device fail at least once\n",
    "\n",
    "~10% device failing\n",
    "\n",
    "'only' 106 positive points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-20T18:12:28.723917",
     "start_time": "2017-01-20T18:12:28.707260"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates = label_dset.index.get_level_values(0)\n",
    "print \"Range: from %s to %s\" % (dates.min(), dates.max())\n",
    "\n",
    "\n",
    "total_failures_per_date = label_dset.groupby(level=0).agg(sum)\n",
    "print\n",
    "print \" n failures per date\"\n",
    "print str(total_failures_per_date[\"failure\"].value_counts())\n",
    "print\n",
    "print \"total: %i failures for %i days\" % (total_failures_per_date[\"failure\"].sum(), \n",
    "                                          total_failures_per_date[total_failures_per_date.failure >0].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-20T18:12:29.790747",
     "start_time": "2017-01-20T18:12:29.720487"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure\n",
    "data =total_failures_per_date.resample(\"M\").sum() \n",
    "test = label_dset.reset_index(\"device\").resample(\"M\").agg(lambda d : d.nunique())\n",
    "data[\"n_devices\"] = test[\"device\"]\n",
    "data[\"failure_ratio_percent\"] = data[\"failure\"] / data[\"n_devices\"] * 100\n",
    "data.index = (calendar.month_abbr[i] for i in data.index.month)\n",
    "l = Line(\n",
    "    data[\"failure_ratio_percent\"],\n",
    "    title=\"failures per Month\",\n",
    "    ylabel=\"% failure\", \n",
    "    xlabel=\"month\"\n",
    ")\n",
    "show(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = Line(\n",
    "    data[\"n_devices\"],\n",
    "    title=\"n devices seen per Month\",\n",
    "    ylabel=\"n_devices\", \n",
    "    xlabel=\"month\"\n",
    ")\n",
    "show(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-20T18:12:31.192542",
     "start_time": "2017-01-20T18:12:31.175466"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weekday_dset = total_failures_per_date.copy()\n",
    "weekday_dset.index = [\"%i:%s\" % (i,calendar.day_name[i]) for i in total_failures_per_date.index.weekday]\n",
    "\n",
    "per_day = weekday_dset.groupby(level=0).sum()\n",
    "\n",
    "print \"failures per weekday\"\n",
    "\n",
    "per_day.sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "# uncomment to print \"markdown-compatible\" output\n",
    "#d = per_day.sort_index()\n",
    "#print tabulate(d , headers = [\"weekday\",\"NB failures\" ],tablefmt=\"pipe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- Long term trend with more failures in the past\n",
    "- Less  failures over the weekend\n",
    "- The absence of weekend could be explained by maintenance hapening only during workweek (hence explaing more failures on monday\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Per Device description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-20T18:12:33.367085",
     "start_time": "2017-01-20T18:12:33.318047"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dates = label_dset.swaplevel().reset_index(\"date\")\n",
    "dd= dates[\"date\"]\n",
    "devices = pd.DataFrame({\"min_date\":dd.groupby(level=0).min(),\"failure\":dates[\"failure\"].groupby(level=0).sum()})\n",
    "devices[\"max_date\"] =  dd.groupby(level=0).max()\n",
    "devices[\"n_lines\"] = dd.groupby(level=0).count()\n",
    "devices[\"n_days\"] = (devices[\"max_date\"] - devices[\"min_date\"] ) /np.timedelta64(1, 'D') +1\n",
    "devices[\"missing_values\"] = devices[\"n_days\"] - devices[\"n_lines\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-20T18:12:34.181907",
     "start_time": "2017-01-20T18:12:34.151153"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "devices[\"min_date\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking the nb devices per month. this is better done above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-20T18:12:35.324533",
     "start_time": "2017-01-20T18:12:35.312165"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame({\"n_devices\":devices[\"max_date\"].dt.month.value_counts().sort_index()})\n",
    "montlhy_devices = pd.DataFrame({\"n_devices\":devices[\"max_date\"].dt.month.value_counts().sort_index()})\n",
    "montlhy_devices.index = [calendar.month_abbr[i] for i in montlhy_devices.index]\n",
    "montlhy_devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bucketing the n devices with missing day data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-20T18:12:37.045383",
     "start_time": "2017-01-20T18:12:37.036754"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = ( (devices[\"missing_values\"] //20)*20).value_counts()\n",
    "#i = ( (devices[\"missing_values\"])).value_counts(bins=10)\n",
    "i.index.name = \"n missing days\"\n",
    "pd.DataFrame({\"n devices\":i.sort_index()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-20T18:33:58.613534",
     "start_time": "2017-01-20T18:33:58.372474"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = devices[\"n_days\"].value_counts(bins=10).sort_index()\n",
    "i.index.name='n_days'\n",
    "b = Bar(pd.DataFrame(\n",
    "    {\"n_devices\":i}),\n",
    "    xlabel=\"n days\",\n",
    "   title=\"devices distributed by ndays\"\n",
    "       )\n",
    "show(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "failing_devices = devices[devices[\"failure\"]>0].index\n",
    "failing_devices_t = pd.DataFrame({\"failure\":label_dset[\"failure\"].unstack().filter(items=failing_devices).unstack()}).dropna()\n",
    "def max_date(date):\n",
    "    return np.max(date)\n",
    "\n",
    "def failing_date(date):\n",
    "    data = withdate.ix[date.index]\n",
    "    return data[data[\"failure\"]>0][\"date\"][0]\n",
    "\n",
    "withdate = failing_devices_t.reset_index(level=1)\n",
    "max_vs_failingdates = withdate.groupby(level=0).agg( {\"date\": [ max_date, failing_date ],\"failure\": np.sum})\n",
    "max_vs_failingdates.columns = max_vs_failingdates.columns.droplevel()\n",
    "max_vs_failingdates[\"td\"] = (max_vs_failingdates[\"max_date\"] - max_vs_failingdates[\"failing_date\"]) / np.timedelta64(1, 'D')\n",
    "print\n",
    "print \"dt in days between first failure and end of measurement :\"\n",
    "print max_vs_failingdates[\"td\"].value_counts()\n",
    "print\n",
    "print \"n failures\"\n",
    "print max_vs_failingdates[\"sum\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"looking at weird failures\"\n",
    "weird_devices = max_vs_failingdates[max_vs_failingdates[\"td\"] > 0]\n",
    "weirdos = failing_devices_t.reset_index(level=1).ix[set(weird_devices.index)]\n",
    "print weirdos.set_index(\"date\",append=True).unstack(level=\"device\").to_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - indetified a list of devices, which are still measured after having failed.\n",
    " \n",
    "three hypothesis:\n",
    " - The device is still functionnal after maintenance\n",
    " - The failure was a fluke\n",
    " - The measurement thereafter are false\n",
    " \n",
    " ==> if we cannot distinguish between these hypothesis, need to remove these devices from the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
